{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c19da3f-2d12-47c0-a06c-50becc52a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class pMHCDataset(Dataset):\n",
    "    def __init__(self, root, filename, aaindex, transform=None, pre_transform=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.filename = filename\n",
    "        self.aaindex = aaindex\n",
    "        super(pMHCDataset, self).__init__(root, transform, pre_transform)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in processed_dir, processing is skipped\"\"\"\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
    "        return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass##不需要下载\n",
    "    \n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        for index, sample in tqdm(self.data.iterrows(), total=self.data.shape[0]):#tqdm可以显示运行进程\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(sample[\"pep\"],sample[\"hla_seq\"],self.aaindex)\n",
    "            edge_index = self._get_edge_index(sample[\"pep\"],sample[\"hla_seq\"])\n",
    "            label = self._get_labels(sample[\"type\"])\n",
    "            # Create data object\n",
    "            data = Data(x=node_feats, edge_index=edge_index, y=label, index=0) \n",
    "            torch.save(data, os.path.join(self.processed_dir, f'data_{index}.pt'))\n",
    "\n",
    "    def _get_node_features(self, pep, HLA, aaindex):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of Nodes, Node Feature size]\n",
    "        \"\"\"\n",
    "        all_seq = pep + HLA\n",
    "        all_node_feats = []\n",
    "        for index, aa in enumerate(all_seq):\n",
    "            node_feats = []\n",
    "            ##aaindex\n",
    "            node_feats.extend(aaindex[aa].to_list())\n",
    "            anchar = [0,len(pep)]\n",
    "            seq_onehot = [0,0]\n",
    "            seq_onehot[sum([index >= i for i in anchar])-1] = 1\n",
    "            node_feats.extend(seq_onehot)\n",
    "            all_node_feats.append(node_feats)\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats)\n",
    "        \n",
    "    \n",
    "    def _get_labels(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label)\n",
    "    \n",
    "    def _get_edge_index(self, pep, hla):\n",
    "        ##生成边\n",
    "        nodes = list(range(0,len(pep)+len(hla)))\n",
    "        edge_index = [[],[]]  \n",
    "        for i,_ in enumerate(pep):\n",
    "            nodes_cp = copy.deepcopy(nodes)\n",
    "            nodes_cp.remove(i)\n",
    "            edge_index[0].extend([i]*(len(nodes)-1))\n",
    "            edge_index[1].extend(nodes_cp)\n",
    "        for i,_ in enumerate(hla):\n",
    "            i = i + len(pep)\n",
    "            nodes_cp = copy.deepcopy(nodes)\n",
    "            nodes_cp.remove(i)\n",
    "            edge_index[0].extend([i]*(len(nodes)-1))\n",
    "            edge_index[1].extend(nodes_cp)  \n",
    "        edge_index = torch.tensor(edge_index)\n",
    "        return edge_index\n",
    "    \n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt')) \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7386e8c3-bf2b-4738-bb9f-58301bad29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaindex = pd.read_csv(\"../data/aaindex1_pca.csv\")\n",
    "train_dt = pMHCDataset(root=\"../data/models/train_data/\",\n",
    "                       filename=\"train_data_iedb_2.csv\",\n",
    "                       aaindex=aaindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d4ac66-31e1-401a-8d50-58e410f9dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##model\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling, GraphNorm\n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList, LeakyReLU\n",
    "from gtrick import random_feature\n",
    "from gtrick.pyg import VirtualNode\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn import MemPooling\n",
    "from torch.nn import LeakyReLU\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, model_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        embedding_size = model_params[\"model_embedding_size\"]\n",
    "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "        n_heads = model_params[\"model_heads\"]\n",
    "        n_layers = model_params[\"model_layers\"]\n",
    "        self.n_layers = n_layers\n",
    "        self.top_k_every_n = 1\n",
    "        self.conv_layers = ModuleList([])\n",
    "        self.transf_layers = ModuleList([])\n",
    "        self.pooling_layers = ModuleList([])\n",
    "        self.bn_layers = ModuleList([])\n",
    "        self.vns = ModuleList()\n",
    "        self.relu = LeakyReLU()\n",
    "\n",
    "        # Transformation layer\n",
    "        self.conv1 = TransformerConv(feature_size, \n",
    "                                    embedding_size, \n",
    "                                    heads=n_heads,\n",
    "                                    beta=True) \n",
    "\n",
    "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "        self.bn1 =  GraphNorm(embedding_size)\n",
    "        # Other layers\n",
    "        for i in range(n_layers):\n",
    "            self.conv_layers.append(TransformerConv(embedding_size, \n",
    "                                                    embedding_size, \n",
    "                                                    heads=n_heads,\n",
    "                                                    beta=True))\n",
    "\n",
    "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "            self.bn_layers.append(GraphNorm(embedding_size))\n",
    "            self.vns.append(VirtualNode(embedding_size, embedding_size))\n",
    "            \n",
    "\n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, 1)  \n",
    "\n",
    "    def forward(self, x, edge_index, batch_index, node_index):\n",
    "        # Initial transformation\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(self.transf1(x))\n",
    "        x = self.bn1(x, batch_index)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x, vx = self.vns[i].update_node_emb(x, edge_index, batch_index)\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = self.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x, batch_index)\n",
    "            vx = self.vns[i].update_vn_emb(x, batch_index, vx)\n",
    "        \n",
    "        #x = x[node_index,:]\n",
    "        # Output block\n",
    "        x = self.relu(self.linear1(vx))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba66bf1e-dbd1-4df5-b8a8-18f5337572e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(f\"{type}, Epoch: {epoch}: \")\n",
    "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_true, y_pred)}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_pred)\n",
    "        print(f\"ROC AUC: {roc}\")\n",
    "    except:\n",
    "        print(f\"ROC AUC: notdefined\")\n",
    "    return prec, rec, roc\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for _, batch in enumerate(tqdm(train_loader)): \n",
    "        #remove = batch[1]\n",
    "        target = batch.y\n",
    "        input_x = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        target = target.to(device)\n",
    "        input_x = input_x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        batch_index = batch.batch.to(device)\n",
    "        node_index = batch.index.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        pred = model(input_x.float(), edge_index, batch_index, node_index) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(pred, target.reshape(pred.shape[0],1).float())\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    prec, rec, roc = calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss/step, prec, rec, roc\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        target = batch.y\n",
    "        input_x = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        target = target.to(device)\n",
    "        input_x = input_x.to(device)\n",
    "        edge_index = edge_index.to(device)\n",
    "        batch_index = batch.batch.to(device)\n",
    "        node_index = batch.index.to(device)\n",
    "        pred = model(input_x.float(), edge_index, batch_index, node_index) \n",
    "        loss = loss_fn(pred, target.reshape(pred.shape[0],1).float())\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "        \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    prec, rec, roc = calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    return running_loss/step, prec, rec, roc\n",
    "\n",
    "# %% Run the training\n",
    "def run_one_training(params, train_dt, loss_fn, writer):\n",
    "\n",
    "    # Prepare training\n",
    "    train_loader = DataLoader(train_dt, batch_size=params[\"batch_size\"], num_workers = 20, pin_memory=True, shuffle=True)\n",
    "    #test_loader = DataLoader(test_dt, batch_size=params[\"batch_size\"], num_workers = 20, pin_memory=True, shuffle=True)\n",
    "\n",
    "    # Loading the model\n",
    "    print(\"Loading model...\")\n",
    "    model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}\n",
    "    model = GNN(feature_size=22, model_params=model_params) \n",
    "    model = model.to(device)\n",
    "    print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "\n",
    "    # < 1 increases precision, > 1 recall\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                lr=params[\"learning_rate\"],\n",
    "                                weight_decay=params[\"weight_decay\"])\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=params[\"scheduler_gamma\"])\n",
    "\n",
    "    # Start training\n",
    "    for epoch in range(36): \n",
    "        # Training\n",
    "        model.train()\n",
    "        loss, prec, rec, roc = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
    "        print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
    "        writer.add_scalar(\"Train/Loss\", loss, epoch)\n",
    "        # Testing\n",
    "        #if epoch % 5 == 0:\n",
    "        #    model.eval()\n",
    "        #    loss, prec, rec, roc = test(epoch, model, test_loader, loss_fn)\n",
    "        #    print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f649aa-4681-4702-bd4e-134aa7f07e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Number of parameters: 273089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:57<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 0: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3040 1905]\n",
      " [1098 2369]]\n",
      "F1 Score: 0.6120656245963054\n",
      "Accuracy: 0.6430099857346647\n",
      "Precision: 0.5542817033224146\n",
      "Recall: 0.6832996827228152\n",
      "ROC AUC: 0.6490310344857757\n",
      "Epoch 0 | Train Loss 0.731081186308607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:54<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 1: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3232 1713]\n",
      " [ 751 2716]]\n",
      "F1 Score: 0.6879432624113475\n",
      "Accuracy: 0.7070851165002378\n",
      "Precision: 0.6132309776473245\n",
      "Recall: 0.7833862128641477\n",
      "ROC AUC: 0.7184878485958758\n",
      "Epoch 1 | Train Loss 0.6584465550435813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 2: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3359 1586]\n",
      " [ 753 2714]]\n",
      "F1 Score: 0.6988541264323419\n",
      "Accuracy: 0.7219448407037565\n",
      "Precision: 0.6311627906976744\n",
      "Recall: 0.7828093452552639\n",
      "ROC AUC: 0.7310406685831425\n",
      "Epoch 2 | Train Loss 0.6439041010893797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 3: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3318 1627]\n",
      " [ 698 2769]]\n",
      "F1 Score: 0.7043113315528423\n",
      "Accuracy: 0.7236091298145506\n",
      "Precision: 0.6298908098271155\n",
      "Recall: 0.7986732044995674\n",
      "ROC AUC: 0.7348269965874985\n",
      "Epoch 3 | Train Loss 0.6343430633950596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:55<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 4: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3284 1661]\n",
      " [ 652 2815]]\n",
      "F1 Score: 0.7088002014352259\n",
      "Accuracy: 0.7250356633380884\n",
      "Precision: 0.6289097408400357\n",
      "Recall: 0.8119411595038939\n",
      "ROC AUC: 0.7380231581139287\n",
      "Epoch 4 | Train Loss 0.6266339514475359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 5: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3423 1522]\n",
      " [ 740 2727]]\n",
      "F1 Score: 0.7068429237947123\n",
      "Accuracy: 0.7310984308131241\n",
      "Precision: 0.6417980701341492\n",
      "Recall: 0.7865589847130083\n",
      "ROC AUC: 0.7393866713251593\n",
      "Epoch 5 | Train Loss 0.620491536709519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:58<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 6: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3380 1565]\n",
      " [ 690 2777]]\n",
      "F1 Score: 0.7112306313228326\n",
      "Accuracy: 0.7319305753685211\n",
      "Precision: 0.6395670198065407\n",
      "Recall: 0.8009806749351024\n",
      "ROC AUC: 0.7422496903492499\n",
      "Epoch 6 | Train Loss 0.6100686796774429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:57<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 7: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3429 1516]\n",
      " [ 719 2748]]\n",
      "F1 Score: 0.7109041521148622\n",
      "Accuracy: 0.7343081312410842\n",
      "Precision: 0.6444652908067542\n",
      "Recall: 0.7926160946062879\n",
      "ROC AUC: 0.7430218996792815\n",
      "Epoch 7 | Train Loss 0.613002237399948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 8: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3447 1498]\n",
      " [ 703 2764]]\n",
      "F1 Score: 0.7152283607193687\n",
      "Accuracy: 0.7383499762244413\n",
      "Precision: 0.6485218207414359\n",
      "Recall: 0.797231035477358\n",
      "ROC AUC: 0.7471493903372634\n",
      "Epoch 8 | Train Loss 0.6049348601766865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:50<00:00, 20.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 9: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3507 1438]\n",
      " [ 724 2743]]\n",
      "F1 Score: 0.7173117154811716\n",
      "Accuracy: 0.7429862101759391\n",
      "Precision: 0.6560631427888065\n",
      "Recall: 0.7911739255840785\n",
      "ROC AUC: 0.7501875694654467\n",
      "Epoch 9 | Train Loss 0.600368035553526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:57<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 10: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3494 1451]\n",
      " [ 680 2787]]\n",
      "F1 Score: 0.7234263465282285\n",
      "Accuracy: 0.7466714217784118\n",
      "Precision: 0.6576215195847098\n",
      "Recall: 0.8038650129795212\n",
      "ROC AUC: 0.755218654113623\n",
      "Epoch 10 | Train Loss 0.5946313865454478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 11: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3504 1441]\n",
      " [ 731 2736]]\n",
      "F1 Score: 0.7158555729984301\n",
      "Accuracy: 0.7417974322396577\n",
      "Precision: 0.6550155614077089\n",
      "Recall: 0.7891548889529852\n",
      "ROC AUC: 0.7488747144461589\n",
      "Epoch 11 | Train Loss 0.5995374696024697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 12: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3554 1391]\n",
      " [ 720 2747]]\n",
      "F1 Score: 0.7224194608809994\n",
      "Accuracy: 0.7490489776509748\n",
      "Precision: 0.6638472692121798\n",
      "Recall: 0.792327660801846\n",
      "ROC AUC: 0.7555167120996085\n",
      "Epoch 12 | Train Loss 0.5952884511236002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:53<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 13: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3577 1368]\n",
      " [ 741 2726]]\n",
      "F1 Score: 0.721068641714059\n",
      "Accuracy: 0.7492867332382311\n",
      "Precision: 0.6658524670249145\n",
      "Recall: 0.7862705509085665\n",
      "ROC AUC: 0.7548137385483176\n",
      "Epoch 13 | Train Loss 0.5893776307144546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:47<00:00, 22.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 14: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3625 1320]\n",
      " [ 729 2738]]\n",
      "F1 Score: 0.7277076411960133\n",
      "Accuracy: 0.7564194008559201\n",
      "Precision: 0.6747166091670774\n",
      "Recall: 0.789731756561869\n",
      "ROC AUC: 0.7613977286348272\n",
      "Epoch 14 | Train Loss 0.5881547904343206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:46<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 15: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3559 1386]\n",
      " [ 726 2741]]\n",
      "F1 Score: 0.7218856992362391\n",
      "Accuracy: 0.7489300998573466\n",
      "Precision: 0.664162830142961\n",
      "Recall: 0.7905970579751946\n",
      "ROC AUC: 0.7551569718591848\n",
      "Epoch 15 | Train Loss 0.5775493247710707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 16: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3621 1324]\n",
      " [ 713 2754]]\n",
      "F1 Score: 0.7300198807157058\n",
      "Accuracy: 0.7578459343794579\n",
      "Precision: 0.6753310446297205\n",
      "Recall: 0.7943466974329392\n",
      "ROC AUC: 0.7633007501320409\n",
      "Epoch 16 | Train Loss 0.5764632602381615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 17: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3635 1310]\n",
      " [ 742 2725]]\n",
      "F1 Score: 0.7264729405491868\n",
      "Accuracy: 0.7560627674750356\n",
      "Precision: 0.6753407682775713\n",
      "Recall: 0.7859821171041246\n",
      "ROC AUC: 0.760534031251759\n",
      "Epoch 17 | Train Loss 0.5828078484778848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:46<00:00, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 18: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3641 1304]\n",
      " [ 722 2745]]\n",
      "F1 Score: 0.7304417243214477\n",
      "Accuracy: 0.7591535901093676\n",
      "Precision: 0.6779451716473204\n",
      "Recall: 0.7917507931929623\n",
      "ROC AUC: 0.7640250427036601\n",
      "Epoch 18 | Train Loss 0.5789848621297246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 19: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3681 1264]\n",
      " [ 710 2757]]\n",
      "F1 Score: 0.7363782051282052\n",
      "Accuracy: 0.7653352353780314\n",
      "Precision: 0.6856503357373788\n",
      "Recall: 0.7952119988462648\n",
      "ROC AUC: 0.7698001349135268\n",
      "Epoch 19 | Train Loss 0.5711950442608545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:53<00:00, 19.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 20: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3628 1317]\n",
      " [ 737 2730]]\n",
      "F1 Score: 0.726643598615917\n",
      "Accuracy: 0.7558250118877794\n",
      "Precision: 0.6745737583395107\n",
      "Recall: 0.787424286126334\n",
      "ROC AUC: 0.760547330120801\n",
      "Epoch 20 | Train Loss 0.5814627334192225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 21: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3706 1239]\n",
      " [ 739 2728]]\n",
      "F1 Score: 0.7339252085014797\n",
      "Accuracy: 0.7648597242035188\n",
      "Precision: 0.6876733047643055\n",
      "Recall: 0.7868474185174502\n",
      "ROC AUC: 0.768145650613629\n",
      "Epoch 21 | Train Loss 0.5706989862336406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 22: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3692 1253]\n",
      " [ 698 2769]]\n",
      "F1 Score: 0.7394845773801576\n",
      "Accuracy: 0.7680694246314789\n",
      "Precision: 0.6884634510193933\n",
      "Recall: 0.7986732044995674\n",
      "ROC AUC: 0.7726429723205623\n",
      "Epoch 22 | Train Loss 0.5705427612273639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:48<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 23: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3684 1261]\n",
      " [ 729 2738]]\n",
      "F1 Score: 0.7334583444950442\n",
      "Accuracy: 0.7634331906799809\n",
      "Precision: 0.684671167791948\n",
      "Recall: 0.789731756561869\n",
      "ROC AUC: 0.7673633504750699\n",
      "Epoch 23 | Train Loss 0.5689839917047396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 24: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3700 1245]\n",
      " [ 720 2747]]\n",
      "F1 Score: 0.7365598605711221\n",
      "Accuracy: 0.7664051355206848\n",
      "Precision: 0.68812625250501\n",
      "Recall: 0.792327660801846\n",
      "ROC AUC: 0.7702790983483446\n",
      "Epoch 24 | Train Loss 0.5648963202513443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:49<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 25: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3709 1236]\n",
      " [ 719 2748]]\n",
      "F1 Score: 0.7376191115286539\n",
      "Accuracy: 0.7675939134569663\n",
      "Precision: 0.6897590361445783\n",
      "Recall: 0.7926160946062879\n",
      "ROC AUC: 0.771333325361789\n",
      "Epoch 25 | Train Loss 0.5628265371482408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:51<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 26: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3656 1289]\n",
      " [ 711 2756]]\n",
      "F1 Score: 0.7337593184238551\n",
      "Accuracy: 0.7622444127436995\n",
      "Precision: 0.6813349814585908\n",
      "Recall: 0.7949235650418229\n",
      "ROC AUC: 0.7671281121467963\n",
      "Epoch 26 | Train Loss 0.5631183696620364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:53<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 27: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3744 1201]\n",
      " [ 711 2756]]\n",
      "F1 Score: 0.7424568965517242\n",
      "Accuracy: 0.7727056585829767\n",
      "Precision: 0.696487237806419\n",
      "Recall: 0.7949235650418229\n",
      "ROC AUC: 0.7760259887898701\n",
      "Epoch 27 | Train Loss 0.5607368143934034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:52<00:00, 19.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 28: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3728 1217]\n",
      " [ 672 2795]]\n",
      "F1 Score: 0.7474261264874983\n",
      "Accuracy: 0.7754398478364242\n",
      "Precision: 0.6966600199401795\n",
      "Recall: 0.8061724834150562\n",
      "ROC AUC: 0.7800326522232005\n",
      "Epoch 28 | Train Loss 0.5514995218343155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 29: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3743 1202]\n",
      " [ 738 2729]]\n",
      "F1 Score: 0.7377669640443363\n",
      "Accuracy: 0.7693770803613885\n",
      "Precision: 0.6942253879419995\n",
      "Recall: 0.7871358523218921\n",
      "ROC AUC: 0.7720310201953242\n",
      "Epoch 29 | Train Loss 0.5548050052737782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 30: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3739 1206]\n",
      " [ 688 2779]]\n",
      "F1 Score: 0.7458400429414922\n",
      "Accuracy: 0.7748454588682834\n",
      "Precision: 0.6973651191969887\n",
      "Recall: 0.8015575425439861\n",
      "ROC AUC: 0.7788374163680497\n",
      "Epoch 30 | Train Loss 0.5547089708735281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 31: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3712 1233]\n",
      " [ 691 2776]]\n",
      "F1 Score: 0.7426431246655965\n",
      "Accuracy: 0.7712791250594389\n",
      "Precision: 0.6924420054876528\n",
      "Recall: 0.8006922411306605\n",
      "ROC AUC: 0.7756747353277165\n",
      "Epoch 31 | Train Loss 0.5478256116886783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:51<00:00, 20.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 32: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3742 1203]\n",
      " [ 741 2726]]\n",
      "F1 Score: 0.7371552190373173\n",
      "Accuracy: 0.7689015691868759\n",
      "Precision: 0.693815220157801\n",
      "Recall: 0.7862705509085665\n",
      "ROC AUC: 0.7714972572540809\n",
      "Epoch 32 | Train Loss 0.5535343329036191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 33: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3739 1206]\n",
      " [ 728 2739]]\n",
      "F1 Score: 0.7390717754991905\n",
      "Accuracy: 0.7700903471231574\n",
      "Precision: 0.694296577946768\n",
      "Recall: 0.7900201903663109\n",
      "ROC AUC: 0.7730687402792121\n",
      "Epoch 33 | Train Loss 0.559595361989374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 34: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3735 1210]\n",
      " [ 679 2788]]\n",
      "F1 Score: 0.74695244474213\n",
      "Accuracy: 0.7754398478364242\n",
      "Precision: 0.6973486743371686\n",
      "Recall: 0.804153446783963\n",
      "ROC AUC: 0.7797309195497166\n",
      "Epoch 34 | Train Loss 0.552113721791669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1052/1052 [00:56<00:00, 18.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, Epoch: 35: \n",
      "\n",
      " Confusion matrix: \n",
      " [[3747 1198]\n",
      " [ 675 2792]]\n",
      "F1 Score: 0.7488266058736757\n",
      "Accuracy: 0.7773418925344746\n",
      "Precision: 0.699749373433584\n",
      "Recall: 0.8053071820017306\n",
      "ROC AUC: 0.7815211339735649\n",
      "Epoch 35 | Train Loss 0.5449835354242715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "HYPERPARAMETERS = {\n",
    "    \"batch_size\": 8,\n",
    "    \"weight_decay\": 0.00001,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"model_embedding_size\": 64, \n",
    "    \"model_dense_neurons\": 32,\n",
    "    \"model_heads\":3,\n",
    "    \"model_layers\":3\n",
    "}\n",
    "writer = SummaryWriter(f\"/root/tf-logs/gnn_neo_loss\")\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(1.4))\n",
    "model_last = run_one_training(HYPERPARAMETERS,train_dt,loss_fn,writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bff8ba6-6ff6-4b8e-8ce1-fa352dda2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_last.state_dict(), \"../data/models/gnn_full_model_ext.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf7bfa0-bf72-402f-8914-0f30e3ff5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|██████████| 1438/1438 [00:05<00:00, 260.94it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "###预测\n",
    "dt = pd.read_csv(\"../data/tesla_val.csv\")\n",
    "val_dt = pMHCDataset(root=\"../data/models/val_data/\",\n",
    "                       filename=\"db_pre_dt.csv\",\n",
    "                       aaindex=aaindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd5c250a-4698-4932-832d-d91e1f60222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 17.01it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(val_dt, batch_size=64, shuffle=False)\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for _, batch in enumerate(tqdm(data_loader)):\n",
    "    target = batch.y\n",
    "    input_x = batch.x\n",
    "    edge_index = batch.edge_index\n",
    "    target = target.to(device)\n",
    "    input_x = input_x.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    batch_index = batch.batch.to(device)\n",
    "    node_index = batch.index.to(device)\n",
    "    model_last.eval()\n",
    "    pred = model_last(input_x.float(), edge_index, batch_index, node_index) \n",
    "    all_preds.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
    "    all_labels.append(target.cpu().detach().numpy())\n",
    "all_preds = np.concatenate(all_preds).ravel()\n",
    "all_labels = np.concatenate(all_labels).ravel()\n",
    "pred = pd.DataFrame({\"all_preds\":all_preds,\"all_labels\":all_labels})\n",
    "pred.to_csv(\"../data/db_pred_gnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d8f9b2f-23d7-46c0-847d-1fc936ced480",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_last, \"../data/models/last_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
